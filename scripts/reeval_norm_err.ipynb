{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/esat/rooster/gkouros/projects/nerf-repos/nmf\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import imageio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"] = \"1\"\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import yaml\n",
    "from icecream import ic\n",
    "\n",
    "import sys\n",
    "base_path = Path(os.path.abspath('')).parent\n",
    "print(base_path)\n",
    "sys.path.append(str(base_path))\n",
    "import torch\n",
    "from dataLoader import dataset_dict\n",
    "\n",
    "def disp_im(im):\n",
    "    plt.close()\n",
    "    plt.cla()\n",
    "    fig = plt.imshow(im)\n",
    "    plt.close()\n",
    "    display(fig.figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(p):\n",
    "    stats_files = ['stats_augnle.yaml', 'stats_augnl.yaml', 'stats_augn.yaml', 'stats_aug.yaml', 'stats.yaml']\n",
    "    stat_file = [s for s in stats_files if (p / \"imgs_test_all\" / s).exists()]\n",
    "    stat_file = stat_file[0] if len(stat_file) else None\n",
    "    if stat_file is None:\n",
    "        return None\n",
    "    data_path = p / \"imgs_test_all\" / stat_file\n",
    "    with data_path.open('r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logs/smoothing/teapot_15687\n",
      "../logs/smoothing/toaster_15688\n",
      "../logs/smoothing/renault_segmented_15691\n",
      "../logs/smoothing/tesla_segmented_15692\n",
      "../logs/smoothing/ball_15694\n",
      "Original Image size: 800 x 800\n",
      "Image size: 800 x 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.fx: 1250.0000504168488, self.fy: 1250.0000504168488\n",
      "ic| self.intrinsics: tensor([[1.2500e+03, 0.0000e+00, 4.0000e+02],\n",
      "                             [0.0000e+00, 1.2500e+03, 4.0000e+02],\n",
      "                             [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n",
      "Loading data test (200): 100%|██████████| 200/200 [00:07<00:00, 26.11it/s]\n",
      "/tmp/ipykernel_1503773/2000447522.py:38: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  pnorms = torch.as_tensor(imageio.imread(p / \"imgs_test_all\" / \"world_normal\" / f\"{idx:03d}.png\")).float()\n",
      "ic| self.fx: 1250.0000504168488, self.fy: 1250.0000504168488\n",
      "ic| self.intrinsics: tensor([[1.2500e+03, 0.0000e+00, 4.0000e+02],\n",
      "                             [0.0000e+00, 1.2500e+03, 4.0000e+02],\n",
      "                             [0.0000e+00, 0.0000e+00, 1.0000e+00]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logs/smoothing/helmet_15686\n",
      "../logs/smoothing/coffee_15685\n",
      "../logs/smoothing/car_debug\n",
      "../logs/smoothing/ball_15695\n",
      "Original Image size: 800 x 800\n",
      "Image size: 800 x 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data test (200): 100%|██████████| 200/200 [00:04<00:00, 48.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logs/smoothing/ball_15683\n",
      "../logs/smoothing/car_15684\n",
      "../logs/smoothing/renault_15689\n",
      "../logs/smoothing/tesla_15690\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# log_dir = Path(\"../log\") / \"tensorf\"\n",
    "# log_dir = Path(\"../log\") / \"fixedmip128\"\n",
    "# log_dir = Path(\"../log\") / \"singlebounce_samen\"\n",
    "# exps = [\"noprednorms_nl0_conserve_pb0\", 'fixedmip128', 'tensorf', 'singlebounce_samen']\n",
    "# exps = ['interpdiffuse', 'interpdiffuse_flipnorm', 'fixedmip128', 'tensorf', 'singlebounce_samen']\n",
    "# exps = ['fixedmip']\n",
    "# exps = ['nodiffuse', 'fixedmip', 'noconv']\n",
    "# exps = ['test_exps']\n",
    "# exps = ['fresnel_nointim', 'fresnel_nobounce', 'fresnel', 'lambda', 'fresnel_nonumer']\n",
    "# exps = ['ball_15683', 'car_15684', 'coffee_15685', 'helmet_15686', 'teapot_15687', 'toaster_15688']\n",
    "exps = ['smoothing']\n",
    "# datadir = \"/optane/nerf_datasets\"\n",
    "datadir = '/esat/topaz/gkouros/datasets/nerf'\n",
    "# datadir = \"/data\"\n",
    "for exp in exps:\n",
    "    log_dir = Path(\"../logs\") / exp\n",
    "    for p in log_dir.glob(\"*\"):\n",
    "        print(p)\n",
    "        pano_path = p / \"imgs_test_all\" / \"envmaps\" / \"pano.exr\"\n",
    "        mapped_pano_path = p / \"imgs_test_all\" / \"envmaps\" / \"mapped_pano.png\"\n",
    "        old_data = get_stats(p)\n",
    "        new_data_path = p / \"imgs_test_all\" / \"stats_augnle2.yaml\"\n",
    "\n",
    "        if os.path.exists(new_data_path):\n",
    "            continue\n",
    "\n",
    "        config_path = p / 'config.yaml'\n",
    "        if not os.path.exists(config_path):\n",
    "            continue\n",
    "        config = OmegaConf.load(config_path)\n",
    "        dname = Path(config['dataset']['scenedir']).name\n",
    "        white_bg = config.dataset.white_bg if hasattr(config.dataset, 'white_bg') else True\n",
    "        dataset = dataset_dict[config.dataset.dataset_name]\n",
    "        test_dataset = dataset(os.path.join(datadir, config.dataset.scenedir), split='test',\n",
    "                            downsample=config.dataset.downsample_train, is_stack=True, white_bg=white_bg, is_testing=True)\n",
    "        norm_errs = []\n",
    "        for idx in range(len(test_dataset)):\n",
    "            pnorms = torch.as_tensor(imageio.imread(p / \"imgs_test_all\" / \"world_normal\" / f\"{idx:03d}.png\")).float()\n",
    "            pnorms = (pnorms - 128) / 127\n",
    "            # pnorms = pnorms / torch.linalg.norm(pnorms, dim=-1, keepdim=True)\n",
    "            try:\n",
    "                gt_normal = test_dataset.get_normal(idx)\n",
    "            except:\n",
    "                ic(\"HI\")\n",
    "                break\n",
    "\n",
    "            gt_normal = (gt_normal * 127 + 128).int()\n",
    "            gt_normal = (gt_normal - 128) / 127\n",
    "            gt_normal = gt_normal / ((gt_normal**2).sum(dim=-1, keepdim=True)+1e-6).sqrt()\n",
    "            pnorms = pnorms / ((pnorms**2).sum(dim=-1, keepdim=True)+1e-6).sqrt()\n",
    "\n",
    "            norm_err = torch.arccos((pnorms * gt_normal).sum(dim=-1).clip(min=1e-8, max=1-1e-8)) * 180/np.pi\n",
    "            norm_err[torch.isnan(norm_err)] = 0\n",
    "\n",
    "            # f, axs = plt.subplots(2, 2)\n",
    "            # axs[0, 0].imshow(gt_normal)\n",
    "            # axs[1, 0].imshow(norm_err)\n",
    "            # axs[0, 1].imshow((pnorms * gt_normal).sum(dim=-1).clip(min=1e-8, max=1-1e-8))\n",
    "            # axs[1, 1].imshow(norm_err)\n",
    "            # plt.show()\n",
    "            norm_err *= test_dataset.acc_maps[idx].squeeze(-1)\n",
    "            # print(norm_err.mean())\n",
    "            # break\n",
    "\n",
    "            norm_errs.append(norm_err.sum() / test_dataset.acc_maps[idx].sum())\n",
    "        # break\n",
    "        with new_data_path.open('w') as f:\n",
    "            old_data['norm_err'] = float(sum(norm_errs) / len(norm_errs)) if len(norm_errs) > 0 else 0\n",
    "            yaml.dump(old_data, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "31",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "028f34ffe305a9c9d9afad2118f6894d15876b6d4b2e233b2f3e6907c2ac8580"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
